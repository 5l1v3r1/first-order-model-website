<!DOCTYPE html>
<html lang="en">
    <head>
        <title>CVPR 2016</title>
        <!-- Bootstrap Core CSS -->
        <link href="../css/bootstrap.min.css" rel="stylesheet" />
        <link href="../css/bootstrap-social.css" rel="stylesheet" />
        <link href="../css/custom.css" rel="stylesheet" />
        <!-- Custom CSS -->
        <link href="../css/modern-business.css" rel="stylesheet" />
        <!-- Custom Fonts -->
        <link href="../font-awesome/css/font-awesome.min.css" rel="stylesheet" type="text/css" />
		
		<script src="../js/jquery.js"></script>
		<script src="../js/bootstrap.min.js"></script>
    </head>
    <body>
        <!-- Page Content -->
        <div class="container">
            <!-- Marketing Icons Section -->
            <div class="row">
                <h1 class="text-center">Self-Adaptive Matrix Completion for Heart Rate Estimation from Face Videos under Realistic Conditions</h1>
				<h3 class="text-center">Sergey Tulyakov, Xavier Alameda Pineda, Elisa Ricci, Lijun Yin, Jeffrey Cohn and Nicu Sebe</h3>
				<h2 class="text-center">Abstract</h2>
				
				<div class="col-md-8 col-md-8 col-sm-12 col-md-offset-2 col-lg-offset-2 text-justify">
   This paper introduces a novel deep learning framework for image animation. Given an input image with a target object and a driving video sequence depicting a moving object, our framework generates a video in which the target object is <i>animated</i> according to the driving sequence. This is achieved through a deep architecture that decouples appearance and motion information. Our framework consists of three main modules: (i) a Keypoint Detector unsupervisely trained to extract object keypoints, (ii) a Dense Motion prediction network for generating dense heatmaps from sparse keypoints, in order to better encode motion information and (iii) a Motion Transfer Network, which uses the motion heatmaps and appearance information extracted from the input image to synthesize the output frames. We demonstrate the effectiveness of our method on several benchmark datasets, spanning a wide variety of object appearances, and show that our approach outperforms state-of-the-art image animation and video generation methods.
				</div>
            </div>
            <div class="row">
				
                <div class="col-xs-12 col-md-8 col-md-8 col-sm-12 col-md-offset-2 col-lg-offset-2">
                			<h2 class="page-header">Spotlight video</h2>
                            <div class="embed-responsive embed-responsive-16by9">
                                <iframe src="https://www.youtube.com/embed/9JNkSZJuDJ8" frameborder="0" allowfullscreen></iframe>
                            </div>  
							<h2 class="page-header">Citation</h2>
							<div>
								<div class="col-md-3 col-sm-3 col-xs-3">
									<img class="img-responsive img-rounded" src="../images/cvpr-2016.jpg" alt="" />
								</div>
							
								<div>
								<p><strong>
									Self-Adaptive Matrix Completion for Heart Rate Estimation from Face Videos under Realistic Conditions
								</strong></p>
								<p>Sergey Tulyakov, Xavier Alameda Pineda, Elisa Ricci, Lijun Yin, Jeffrey Cohn and Nicu Sebe</p>
								<p class="col-lg-offset-3"><em>Computer Vision and Pattern Recognition, 2016</em></p>
								<br/>	
								<div class="col-lg-4 col-sm-3 col-md-3 col-xs-3">
									<a href="http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Tulyakov_Self-Adaptive_Matrix_Completion_CVPR_2016_paper.pdf">
										<img class="img-responsive img-rounded img-thumbnail" src="../images/cvpr-front.jpg" alt="paper" height="100" />
									</a>
								</div>

								<div class="col-lg-4 col-sm-3 col-md-3 col-xs-3">
									<a href="https://github.com/sergeytulyakov/sergeytulyakov.github.io/raw/master/data/hr-cvpr.pdf">
										<img class="img-responsive img-rounded img-thumbnail" src="../images/cvpr-presentation.png" alt="presentation" height="100"/>
									</a>
								</div>


								<div class="col-lg-4 col-sm-3 col-md-3 col-xs-3">
									<a href="https://github.com/sergeytulyakov/sergeytulyakov.github.io/raw/master/data/cvpr-poster.pdf">
										<img class="img-responsive img-rounded img-thumbnail" src="../images/cvpr-poster.jpg" alt="poster" height="100"/>
									</a>
								</div>
							
								</div>
								
							</div>
							
					</div>  
				
						
            </div>

			
			

            <div class="row">
				
                <div class="col-xs-12 col-md-8 col-md-8 col-sm-12 col-md-offset-2 col-lg-offset-2">
                	<h2 class="page-header">Data</h2>
					<p>
						We report experiments on the newly acquired Multimodal Spontaneous Emotion (MMSE) dataset. In order to obtain the MMSE please contact <a href="http://www.cs.binghamton.edu/~lijun/">Dr. Lijun Yin</a> 
					</p>
				</div>

			</div>

			<div class="row">
				
                <div class="col-xs-12 col-md-8 col-md-8 col-sm-12 col-md-offset-2 col-lg-offset-2">
					
										<div class="col-lg-10 col-sm-10 col-md-10 col-xs-10">				
						<img class="img-responsive" src="../images/cvpr-mmse.jpg" alt="poster"/>
					</div>	
				</div>

			</div>
			
			
			      <!-- Footer -->
			<hr>
			<footer>
				<div class="row">
					<div class="col-lg-12">
						<p><a href="http://stulyakov.com">Sergey Tulyakov</a>, July 2016</p>
					</div>
				</div>
			</footer>
		
    </body>
	

	
</html>

